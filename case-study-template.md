# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я
придумал использовать такую метрику: allocated_memory и время выполнения задачи
## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 2 сек.

Вот как я построил `feedback_loop`: Т.к. завершение программы на полном файле не представляется
возможным, создал файл на 10_000 строк, первоначалные измерения на неоптимизиованом коде - Время
выполнения ~ 1.5 мин., allocated_memory 447_828_982

## Вникаем в детали системы, чтобы найти 20% точек роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*

Вот какие проблемы удалось найти и решить

### Загрузка файла целиком в память
Объем занимаемой памяти до прочтения файла 20 мб, после 492 мб
Чем измерял: запрашивал у системы
Решение: читать файл построчно

### Аллоцируется String: 362888, Array 70965
Чем измерял: MemoryProfiler
allocated_memory 447_828_982
Удалил лишнее разделение строки, String: - 60000
Решение: добавить frozen literal true, String:  - 25000
вынести в константы часто аллоцирующиеся строки, String: - 5000
Заменил в хешах строки на symbol, String: - 3000
Изменил конкатенацию массивов на добаления объекта, Array: - 30000
Время выполнения сократилось до 1 сек.

### Метод collect_stats_from_users занимает 20% pct
Чем измерял: stackprof
Решение: убрал ненужные итерации и переменные, применил Set, провел рефакторинг части кода
отвечающего за сбор даннных, файл на 10_000 строк кода стал обрабатываться менее, чем за 0.1 сеунду,
добавил файл на 100_000, время обработки около 1 сек. Количесвто аллоцированых строк уменьшилось на
100_000, Array - 10_000, allocated_memory 28_810_722

### Метод Data.parse занимет 8 mb
Чем измерял: ruby prof
Решение: Изменил на strftime

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы allocated_memory c 447_828_982 до 2_059_598
Обработка data_large занмает 45 сек времени и около 2гб памяти

## Защита от регресса производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы сделано
Добален тест по времени выполнения программы на 10000 строках
