# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Попытался запустить исходный код и тот самый `data_large.txt`, но спустя примерно 20 минут ожиданий я забросил это дело. Выбрал выборку поменьше (весом ~ 700кб), общее время выполнения кода стало ~ 19 сек. Путем нехитрых вычислений прикинем, что общее время для анализа файла весом в 135 мб составит около 61 минуты.

Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы, я задал цель: файл в итоге не должен открываться больше 5 минут (300 секунд).

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 19-20 секунд.

Вот как я построил `feedback_loop`:

1) Уменьшил размер файла до 700кб (~3000 юзеров)
2) Общее время время выполнения кода стало ~ 19 секунд
3) Каждый раз, внося изменения, проверял их на тесте, который уже был в коде

## Вникаем в детали системы, чтобы найти 20% точек роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался инструментами:

1) встроенный модуль `Benchmark`
2) гем `stackprof`
3) гем `memory_profiler`

Вот какие проблемы удалось найти и решить

### Оптимизация №1
При использовании гема `memory_profiler` было обнаружено, что больше всего памяти было съедено в строке исходного кода `task-1.rb:55`, а именно строка кода `sessions = sessions + [parse_session(line)] if cols[0] == 'session'`, где мы в цикле `file_lines.each` обрабатываем каждую строку на наличие юзера или сессии.
Было решено вместо конкатенации массивов использовать `<<`, т.е. `Array#push`, что существенно снизило память, выделенную на эту операцию (вместо 1119мб стало лишь 37мб).
На общее время выполнения кода это никак не повлияло.

### Оптимизация №2
Далее тот же `memory_profiler` и `stackprof` показывали на другую тяжелую операцию в строке `task-1.rb:101`, а именно `user_sessions = sessions.select { |session| session['user_id'] == user['id'] }`.
Было решено сильно отрефакторить код, вместо создания новых объектов `User` и присваивания им различных параметров, создать хеш `sessions`, где ключом был бы `id` юзера, а значением - строка из файла с текущей сессией.
Начальная итерация по файлу стала выглядить так:

```ruby
  users = []
  unique_browsers = []
  sessions = {}
  total_sessions = 0

  File.read(file).split("\n").each do |line|
    users << parse_user(line) if line.`start_with?`('user')
    next if !line.start_with?('session')

    current_session = parse_session(line)
    sessions[current_session[:user_id]] ||= []
    sessions[current_session[:user_id]] << current_session

    total_sessions += 1
    browser = current_session[:browser].upcase!
    unique_browsers << browser if !unique_browsers.include?(browser)
  end
```
Была убраны лишнии проверки `cols = line.split(',')` -> `if cols[0] == 'user'` или `if cols[0] == 'session'`. Сделал сразу проверку строки `start_with?` на наличие юзера или сессии.
Также сразу считаем общее кол-во сессий и уникальных браузеров.

Были удалены повторяющиеся `collect_stats_from_users`, которые постоянно гоняли `user_objects`, когда можно было по уже готовому массиву `users` пройти один раз, записав все нужные значения для отчета, что и было сделано.

После всех этих манипуляций итоговое время выполнение кода стало ~ 3.15 секунды.

### Оптимизация №3
Далее самой прожорливой строчкой была `task-1.rb:140`, а именно метод `Date#parse`, на который было затрачено 17мб памяти. Путем гугления `Date#parse ruby benchmark` выяснил, что есть быстрее метод - `Date#strptime`. Замена на него снизило выделение памяти до 6.1мб, а общее время выполнения кода стало ~ 2.45 секунд.

## Результаты
До всех изменений общее время выполнения кода было ~ **19 секунд**, памяти выделялось на все это ~ **1685мб**.
После проделанных манипуляций код выполнялся за **2.45 секунды**, а выделение памяти было около **45мб**.

В результате проделанной оптимизации наконец удалось обработать файл с данными.
Код выполнился за **86 секунд**, что считаю более или менее приемлемым результатом.

## Защита от регресса производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы нужно зафиксировать полученные время (+-1 секунда).
