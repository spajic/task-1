# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
* Сначала я написал свой "велосипед", который запускал код несколько раз, измерял время выполнения через `Benchmark.realtime` и считал среднее.
* Но потом я подсмотрел в разборе из второй лекции инструмент `Benchmark.ips` и он мне понравился

В итоге метрика это число итераций в секунду

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста позволяет не допустить изменения логики программы при оптимизации. Но этот тест был на минитесте и я решил переписать его на более привычный мне `RSpec`. В тесте я зафиксиовал что программа возвращает теже результаты и что программа не стала работать медленнее.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 55 секунд.

Вот как я построил `feedback_loop`:
* Все эталонные файлы лежат папке `spec/fixtures`
* Файлы, которые раньше генерировал минитест теперь называются `data.txt` и `reference_result.json`
* Тест smoke_test_spec.rb проверяет что:
** вывод программы все еще соответствует эталонным файлам
** выполнение программы не стало медленее чем было в начале работы (3.5 секунд в моем случае)
* Скрипт `calc_times.rb` считает метрику запуская `Benchmark.ips` по набору файлов от 100 строк до 5к строк
* Запуск всего Feedback-Loop производится одним скриптом `test-it.sh`

## Фиксируем начальное состояние
До начала всяких оптимизаций наша метрика была вот такой
```
Calculating -------------------------------------
                0.1k    495.917  (±11.1%) i/s -      2.433k in   4.998076s
                0.2k    222.219  (± 9.9%) i/s -      1.096k in   5.001490s
                0.3k    136.152  (± 9.5%) i/s -    673.000  in   5.000267s
                0.4k     93.109  (± 9.7%) i/s -    461.000  in   5.010672s
                0.5k     68.628  (± 7.3%) i/s -    341.000  in   5.010336s
                 01k     25.422  (± 3.9%) i/s -    127.000  in   5.014775s
                 02k      8.279  (± 0.0%) i/s -     42.000  in   5.082306s
                 03k      4.093  (± 0.0%) i/s -     21.000  in   5.134921s
                 04k      2.464  (± 0.0%) i/s -     13.000  in   5.281077s
                 05k      1.658  (± 0.0%) i/s -      9.000  in   5.428681s

Comparison:
                0.1k:      495.9 i/s
                0.2k:      222.2 i/s - 2.23x  slower
                0.3k:      136.2 i/s - 3.64x  slower
                0.4k:       93.1 i/s - 5.33x  slower
                0.5k:       68.6 i/s - 7.23x  slower
                 01k:       25.4 i/s - 19.51x  slower
                 02k:        8.3 i/s - 59.90x  slower
                 03k:        4.1 i/s - 121.17x  slower
                 04k:        2.5 i/s - 201.25x  slower
                 05k:        1.7 i/s - 299.06x  slower
```
То есть при увеличении объема в 50 раз метрика ухужшалась почти в 300 раз

## Вникаем в детали системы, чтобы найти 20% точек роста
Для того, чтобы найти "точки роста" для оптимизации я проверял следующие гипотезы

### Приложение тратит время на сборку мусора
Сделал `GC.disable` - гипотеза не потдтвердилась. Сборщик мусора не повлиял на производительность

### Найти самые медленные части системы



Вот какие проблемы удалось найти и решить

### Находка №1
Используя `RubyProf` нахожу что выполняется медленнее всего. 94.11% времени занимает `Array#each`, что логично, потому что мы все время что-то делаем с масивами. Из времени внутри `Array#each` 42.55% занимает `Array#select`, который в коде всего один - значит его и будем оптимизировать в первую очередь
```
users.each do |user|
  ...
  user_sessions = sessions.select { |session| session['user_id'] == user['id'] }  
```
Тут мы имеем дело со вложенным циклом. Решение: вынести расчет пользовательских сессий в предварительный расчет.

После оптимизации этого участка получаем работающие тесты и вот такой отчет
```
Calculating -------------------------------------
                0.1k    532.154  (±11.8%) i/s -      2.602k in   4.996905s
                0.2k    259.963  (±10.4%) i/s -      1.280k in   4.999759s
                0.3k    167.843  (±10.7%) i/s -    825.000  in   5.000048s
                0.4k    122.780  (± 9.8%) i/s -    603.000  in   5.005309s
                0.5k     99.104  (± 9.1%) i/s -    491.000  in   5.005207s
                 01k     45.688  (± 8.8%) i/s -    226.000  in   5.002644s
                 02k     22.265  (± 4.5%) i/s -    111.000  in   5.006596s
                 03k     14.118  (± 7.1%) i/s -     71.000  in   5.043650s
                 04k      9.584  (± 0.0%) i/s -     48.000  in   5.022222s
                 05k      7.319  (± 0.0%) i/s -     37.000  in   5.063886s

Comparison:
                0.1k:      532.2 i/s
                0.2k:      260.0 i/s - 2.05x  slower
                0.3k:      167.8 i/s - 3.17x  slower
                0.4k:      122.8 i/s - 4.33x  slower
                0.5k:       99.1 i/s - 5.37x  slower
                 01k:       45.7 i/s - 11.65x  slower
                 02k:       22.3 i/s - 23.90x  slower
                 03k:       14.1 i/s - 37.69x  slower
                 04k:        9.6 i/s - 55.53x  slower
                 05k:        7.3 i/s - 72.70x  slower
```
То есть при увеличении объема в 50 раз метрика ухужшалась почти в 73 раз, против 300, до оптимизации

Время выполнения прогона для файла 10к строк уменьшилось с 3.5 секунд до 0.3557 - поменяем это в тестах

### Находка №2
Следующий кандидат на улучшение это метод collect_stats_from_users занимающий 43.53% относительного времени.
Убираем повторные вызовы и двойной расчет одного и того же. После оптимизации получаем некоторый прирост
```
Calculating -------------------------------------
                0.1k    587.188  (±12.6%) i/s -      2.850k in   4.997908s
                0.2k    276.606  (±16.6%) i/s -      1.311k in   5.000084s
                0.3k    175.600  (±15.9%) i/s -    846.000  in   5.002895s
                0.4k    135.578  (±14.8%) i/s -    638.000  in   5.000373s
                0.5k    103.587  (±17.4%) i/s -    487.000  in   5.005707s
                 01k     49.748  (±16.1%) i/s -    234.000  in   5.000097s
                 02k     24.272  (± 8.2%) i/s -    121.000  in   5.017043s
                 03k     15.061  (± 6.6%) i/s -     75.000  in   5.016839s
                 04k     10.365  (± 9.6%) i/s -     52.000  in   5.044044s
                 05k      8.533  (± 0.0%) i/s -     43.000  in   5.048907s

Comparison:
                0.1k:      587.2 i/s
                0.2k:      276.6 i/s - 2.12x  slower
                0.3k:      175.6 i/s - 3.34x  slower
                0.4k:      135.6 i/s - 4.33x  slower
                0.5k:      103.6 i/s - 5.67x  slower
                 01k:       49.7 i/s - 11.80x  slower
                 02k:       24.3 i/s - 24.19x  slower
                 03k:       15.1 i/s - 38.99x  slower
                 04k:       10.4 i/s - 56.65x  slower
                 05k:        8.5 i/s - 68.81x  slower
```
Время выполнения прогона для файла 10к строк уменьшилось с 0.3557 секунд до 0.3316 - поменяем это в тестах
Хорошо, но не так здорово как бы хотелось - продолжаю искать дальше.

### Ваша находка №X
О вашей находке №X

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце*

*Какими ещё результами можете поделиться*

## Защита от регресса производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы сделано *то, что вы для этого сделали*
